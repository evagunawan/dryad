#!/usr/bin/env python3
#Author: Kelsey Florek
#email: kelsey.florek@slh.wisc.edu
#description: A pipeline for constructing SNP based and  core gene set reference free phylogenies

import subprocess as sub
import sys, os, time, argparse, datetime
import docker
import multiprocessing as mp
from shutil import copyfile

#local libraries
from app.lib import cpu_count, checkexists, check_update_status
from app.trimming import q_trim
from app.core_genome import core_genome

#setup argparser to display help if no arguments
class MyParser(argparse.ArgumentParser):
    def error(self, message):
        sys.stderr.write('error: %s\n' % message)
        self.print_help()
        sys.exit(2)

#determine command line arguments and get path
parser = MyParser(description='A pipeline for constructing SNP based and reference free phylogenies.')
subparsers= parser.add_subparsers(title='required arguments',metavar='pipeline',dest="subparser_name",required=True)
#core geneome pipeline
parser_cg = subparsers.add_parser('cg', help='reference free core geneome pipeline')
parser_cg.add_argument('reads', type=str,help="text file listing the location of paired reads to be included in the analysis")
parser_cg.add_argument('-o',metavar='output', type=str,help="output directory - defaults to working directory")
parser_cg.add_argument('-t',metavar='threads', type=int,help="number of cpus to use for pipeline",default=4)
#snp pipeline
parser_snp = subparsers.add_parser('snp', help='CFSAN SNP pipeline')
parser_snp.add_argument('reads', type=str,help="text file listing the location of paired reads to be included in the analysis")
parser_snp.add_argument('reference_sequence', type=str,help="reference fasta for SNP tree")
parser_snp.add_argument('-o',metavar='output', type=str,help="output directory - defaults to working directory")
parser_snp.add_argument('-t',metavar='threads', type=int,help="number of cpus to use for pipeline",default=4)

args = parser.parse_args()

pipeline = ''
if args.subparser_name == 'cg':
    pipeline = args.subparser_name

if args.subparser_name == 'snp':
    pipeline = args.subparser_name
    #get reference path
    reference = os.path.abspath(args.reference_sequence)

#common args
threads = args.t
reads_path = args.reads
#get current working dir if output is empty
try:
    out = os.path.abspath(args.o)
except (AttributeError, TypeError) as err:
    out = os.getcwd()

#open file and pull locations into a list
with open(reads_path,'r') as f:
    r_list = []
    for line in f:
        if line.strip() != '':
            r_list.append(line.strip())

#sort and join pairs
r_list.sort()
if len(r_list) % 2 != 0:
    print('There is an uneven number of read pairs in the read list. Exiting.')
    sys.exit()
paired_reads = []
[paired_reads.append([x,y]) for x,y in zip(r_list[0::2],r_list[1::2])]

#get num of jobs and number of cpus per job
jobs,cpu_job = cpu_count(threads)

#check to see if an unfinished job exists
status = ''
status,outdir = check_update_status(out)
if status:
    print("There is a previous unfinished run, do you wish to continue?")
    continue_run = input("Y/N? ")
    if continue_run == 'n' or continue_run == 'N':
        status = ''
        outdir = ''
    elif continue_run == 'y' or continue_run == 'Y':
        pass
    else:
        print("Not a Y/N, exiting!")
        sys.exit()

if status == '':
    #create output dir
    time = datetime.datetime.now()
    str_time = "{0}{1}{2}{3}{4}".format(time.year,time.month,time.day,time.hour,time.minute)
    if checkexists(os.path.join(out,"dryad-"+str_time)):
        print(os.path.join(out,"dryad-"+str_time)+" already exists... exiting.")
        sys.exit()
    outdir = os.path.join(out,"dryad-"+str_time)
    check_update_status(outdir,"start")
    status = 'start'

if status == 'start':
    #start trimming
    status = q_trim(paired_reads,jobs,cpu_job,outdir)
    check_update_status(outdir,"trimm")
    status = "trimm"

if pipeline == 'cg' and status = 'trimm':
    #start core-genome pipeline
    core_genome(jobs,cpu_job,outdir)

#start snp pipeline
